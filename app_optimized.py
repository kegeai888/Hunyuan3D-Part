"""
Hunyuan3D-Part ä¼˜åŒ–ç‰ˆæœ¬ - RTX 4090 GPUåŠ é€Ÿ
é›†æˆFlash Attentionã€æ··åˆç²¾åº¦ã€torch.compileç­‰ä¼˜åŒ–æŠ€æœ¯
"""

import gradio as gr
import os
import sys
import numpy as np
import trimesh
from pathlib import Path
import torch
import pytorch_lightning as pl
import spaces
import time
import logging
from contextlib import contextmanager

# å¯¼å…¥GPUä¼˜åŒ–æ¨¡å—
from gpu_optimizer import RTX4090Optimizer, FlashAttentionOptimizer, gpu_inference_mode

sys.path.append('P3-SAM')
from demo.auto_mask import AutoMask
sys.path.append('XPart')
from partgen.partformer_pipeline import PartFormerPipeline
from partgen.utils.misc import get_config_from_file

# åˆå§‹åŒ–ä¼˜åŒ–å™¨
gpu_optimizer = RTX4090Optimizer()
flash_attn_optimizer = FlashAttentionOptimizer()

# å…¨å±€å˜é‡
automask = None
_PIPELINE = None
output_path = 'P3-SAM/results/gradio'
os.makedirs(output_path, exist_ok=True)

# æ€§èƒ½ç›‘æ§
performance_logger = logging.getLogger("PerformanceMonitor")
performance_logger.setLevel(logging.INFO)

def setup_performance_logging():
    """è®¾ç½®æ€§èƒ½ç›‘æ§æ—¥å¿—"""
    if not performance_logger.handlers:
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '[%(asctime)s] PERF - %(message)s'
        )
        handler.setFormatter(formatter)
        performance_logger.addHandler(handler)

@contextmanager
def timer(operation_name: str):
    """æ€§èƒ½è®¡æ—¶å™¨"""
    start_time = time.time()
    start_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0

    try:
        yield
    finally:
        end_time = time.time()
        end_memory = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0

        elapsed = end_time - start_time
        memory_diff = (end_memory - start_memory) / (1024**2)  # MB

        performance_logger.info(
            f"{operation_name}: {elapsed:.2f}s, Memory: {memory_diff:+.1f}MB"
        )

def initialize_models():
    """å»¶è¿ŸåŠ è½½æ¨¡å‹ï¼Œä½¿ç”¨GPUä¼˜åŒ–"""
    global automask, _PIPELINE

    with timer("æ¨¡å‹åˆå§‹åŒ–"):
        if automask is None:
            with timer("P3-SAMæ¨¡å‹åŠ è½½"):
                automask = AutoMask()
                # ä¼˜åŒ–P3-SAMæ¨¡å‹
                if hasattr(automask, 'model'):
                    automask.model = gpu_optimizer.optimize_model(automask.model)

        if _PIPELINE is None:
            with timer("XPartæ¨¡å‹åŠ è½½"):
                pl.seed_everything(2026, workers=True)
                cfg_path = str(Path(__file__).parent / "XPart/partgen/config" / "infer.yaml")
                config = get_config_from_file(cfg_path)

                assert hasattr(config, "ckpt") or hasattr(
                    config, "ckpt_path"
                ), "ckpt or ckpt_path must be specified in config"

                _PIPELINE = PartFormerPipeline.from_pretrained(
                    config=config,
                    verbose=True,
                    ignore_keys=config.get("ignore_keys", []),
                )

                # GPUä¼˜åŒ–
                device = "cuda" if torch.cuda.is_available() else "cpu"
                _PIPELINE.to(device=device, dtype=torch.float16)  # ä½¿ç”¨FP16

                # ç¼–è¯‘ä¼˜åŒ–ä¸»è¦æ¨¡å‹ç»„ä»¶
                if hasattr(_PIPELINE, 'model') and torch.cuda.is_available():
                    _PIPELINE.model = gpu_optimizer.optimize_model(_PIPELINE.model)

    gpu_optimizer.log_performance_summary()

def is_supported_3d_file(filename):
    """æ£€æŸ¥3Dæ–‡ä»¶æ ¼å¼æ”¯æŒ"""
    if filename is None:
        return False
    ext = os.path.splitext(filename)[1].lower()
    return ext in ['.glb', '.ply', '.obj']

def get_file_info(filename):
    """è·å–æ–‡ä»¶ä¿¡æ¯"""
    if filename is None:
        return "æœªé€‰æ‹©æ–‡ä»¶"
    try:
        file_size = os.path.getsize(filename) / (1024 * 1024)  # MB
        return f"{os.path.basename(filename)} ({file_size:.1f} MB)"
    except:
        return f"{os.path.basename(filename)}"

@spaces.GPU
def segment_mesh_optimized(mesh_path, postprocess=True, postprocess_threshold=0.95, seed=42, progress=gr.Progress()):
    """P3-SAM 3Dæ¨¡å‹åˆ†å‰² - GPUä¼˜åŒ–ç‰ˆæœ¬"""

    with timer("å®Œæ•´åˆ†å‰²æµç¨‹"):
        try:
            # åˆå§‹åŒ–æ¨¡å‹
            progress(0.1, desc="ğŸš€ åˆå§‹åŒ–GPUä¼˜åŒ–æ¨¡å‹...")
            with timer("æ¨¡å‹åˆå§‹åŒ–"):
                initialize_models()

            # éªŒè¯è¾“å…¥
            if mesh_path is None:
                return None, None, None, "âŒ è¯·å…ˆä¸Šä¼ 3Dæ¨¡å‹æ–‡ä»¶"

            if not is_supported_3d_file(mesh_path):
                return None, None, None, "âŒ ä»…æ”¯æŒ .glb, .ply, .obj æ ¼å¼"

            progress(0.2, desc="ğŸ“‚ åŠ è½½3Dæ¨¡å‹...")
            with timer("3Dæ¨¡å‹åŠ è½½"):
                mesh = trimesh.load(mesh_path, force='mesh', process=False)

            progress(0.4, desc="ğŸ” æ‰§è¡ŒGPUåŠ é€Ÿåˆ†å‰²ç®—æ³•...")

            # ä½¿ç”¨GPUä¼˜åŒ–æ¨ç†
            with gpu_inference_mode():
                with timer("P3-SAMæ¨ç†"):
                    aabb, face_ids, mesh = automask.predict_aabb(
                        mesh, seed=seed, is_parallel=False,
                        post_process=postprocess, threshold=postprocess_threshold
                    )

            progress(0.7, desc="ğŸ¨ ç”Ÿæˆåˆ†å‰²ç»“æœ...")
            with timer("ç»“æœåå¤„ç†"):
                # ç”Ÿæˆé¢œè‰²æ˜ å°„ - ä¼˜åŒ–ç‰ˆæœ¬
                color_map = {}
                unique_ids = np.unique(face_ids)

                # ä½¿ç”¨GPUåŠ é€Ÿçš„éšæœºæ•°ç”Ÿæˆ
                if torch.cuda.is_available():
                    colors = torch.rand((len(unique_ids), 3), device='cuda') * 255
                    colors = colors.cpu().numpy()
                else:
                    colors = np.random.rand(len(unique_ids), 3) * 255

                for i, unique_id in enumerate(unique_ids):
                    if unique_id == -1:
                        continue
                    color_map[unique_id] = colors[i]

                # ä¼˜åŒ–çš„é¢ç‰‡é¢œè‰²åˆ†é…
                face_colors = np.array([
                    [50, 50, 50] if fid == -1 else color_map[fid]
                    for fid in face_ids
                ], dtype=np.uint8)

                mesh_save = mesh.copy()
                mesh_save.visual.face_colors = face_colors

            progress(0.9, desc="ğŸ’¾ ä¿å­˜ç»“æœ...")
            with timer("æ–‡ä»¶ä¿å­˜"):
                timestamp = int(time.time())
                file_path = os.path.join(output_path, f'segment_gpu_{timestamp}.glb')
                mesh_save.export(file_path)
                face_id_save_path = os.path.join(output_path, f'face_id_gpu_{timestamp}.npy')
                np.save(face_id_save_path, face_ids)

            # ç»Ÿè®¡åˆ†å‰²ä¿¡æ¯
            num_parts = len(unique_ids) - (1 if -1 in unique_ids else 0)
            gpu_status = gpu_optimizer.get_gpu_status()

            status_msg = (
                f"âœ… GPUåŠ é€Ÿåˆ†å‰²å®Œæˆï¼å…±åˆ†å‰²å‡º {num_parts} ä¸ªéƒ¨åˆ†\n"
                f"ğŸš€ GPUåˆ©ç”¨ç‡: {gpu_status.get('gpu_utilization_percent', 0):.1f}% | "
                f"ğŸ”¥ æ¸©åº¦: {gpu_status.get('temperature_celsius', 0):.1f}Â°C"
            )

            gr_state = [(aabb, mesh_path)]

            progress(1.0, desc="ğŸ‰ å®Œæˆ!")
            return file_path, face_id_save_path, gr_state, status_msg

        except Exception as e:
            gpu_optimizer.clear_memory_if_needed()  # é”™è¯¯æ—¶æ¸…ç†å†…å­˜
            return None, None, None, f"âŒ åˆ†å‰²å¤±è´¥: {str(e)}"

@spaces.GPU(duration=150)
def generate_parts_optimized(mesh_path, seed=42, gr_state=None, progress=gr.Progress()):
    """XPart é›¶ä»¶ç”Ÿæˆ - GPUä¼˜åŒ–ç‰ˆæœ¬"""

    with timer("å®Œæ•´ç”Ÿæˆæµç¨‹"):
        try:
            progress(0.1, desc="ğŸ” éªŒè¯è¾“å…¥...")
            if mesh_path is None:
                return None, None, None, "âŒ è¯·å…ˆä¸Šä¼ 3Dæ¨¡å‹æ–‡ä»¶"

            if gr_state is None or len(gr_state) == 0 or gr_state[0][0] is None:
                return None, None, None, "âŒ è¯·å…ˆæ‰§è¡Œæ¨¡å‹åˆ†å‰²"

            if mesh_path != gr_state[0][1]:
                return None, None, None, "âŒ æ¨¡å‹å·²æ›´æ”¹ï¼Œè¯·é‡æ–°æ‰§è¡Œåˆ†å‰²"

            progress(0.2, desc="ğŸš€ åˆå§‹åŒ–GPUä¼˜åŒ–ç”Ÿæˆæ¨¡å‹...")
            with timer("ç”Ÿæˆæ¨¡å‹åˆå§‹åŒ–"):
                initialize_models()

            aabb = gr_state[0][0]

            progress(0.3, desc="ğŸ² è®¾ç½®éšæœºç§å­...")
            try:
                pl.seed_everything(int(seed), workers=True)
            except Exception:
                pl.seed_everything(2026, workers=True)

            progress(0.5, desc="âš¡ GPUåŠ é€Ÿé›¶ä»¶ç”Ÿæˆï¼ˆé¢„è®¡1-2åˆ†é’Ÿï¼‰...")

            # ä½¿ç”¨GPUä¼˜åŒ–æ¨ç†
            with gpu_inference_mode():
                with timer("XPartæ¨ç†"):
                    additional_params = {"output_type": "trimesh"}

                    # å¯ç”¨æ··åˆç²¾åº¦æ¨ç†
                    with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=torch.cuda.is_available()):
                        obj_mesh, (out_bbox, mesh_gt_bbox, explode_object) = _PIPELINE(
                            mesh_path=mesh_path,
                            aabb=aabb,
                            octree_resolution=512,
                            **additional_params,
                        )

            progress(0.8, desc="ğŸ’¾ ä¿å­˜GPUåŠ é€Ÿç”Ÿæˆç»“æœ...")
            with timer("ç»“æœä¿å­˜"):
                timestamp = int(time.time())
                obj_path = os.path.join(output_path, f'generated_gpu_{timestamp}.glb')
                out_bbox_path = os.path.join(output_path, f'bbox_gpu_{timestamp}.glb')
                explode_path = os.path.join(output_path, f'exploded_gpu_{timestamp}.glb')

                obj_mesh.export(obj_path)
                out_bbox.export(out_bbox_path)
                explode_object.export(explode_path)

            # è·å–æ€§èƒ½ç»Ÿè®¡
            gpu_status = gpu_optimizer.get_gpu_status()

            status_msg = (
                f"âœ… GPUåŠ é€Ÿé›¶ä»¶ç”Ÿæˆå®Œæˆï¼\n"
                f"ğŸš€ GPUåˆ©ç”¨ç‡: {gpu_status.get('gpu_utilization_percent', 0):.1f}% | "
                f"ğŸ’¾ æ˜¾å­˜ä½¿ç”¨: {gpu_status.get('memory_usage_percent', 0):.1f}% | "
                f"ğŸ”¥ æ¸©åº¦: {gpu_status.get('temperature_celsius', 0):.1f}Â°C"
            )

            progress(1.0, desc="ğŸ‰ å®Œæˆ!")
            return obj_path, out_bbox_path, explode_path, status_msg

        except Exception as e:
            gpu_optimizer.clear_memory_if_needed()  # é”™è¯¯æ—¶æ¸…ç†å†…å­˜
            return None, None, None, f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"

def reset_all_optimized():
    """é‡ç½®æ‰€æœ‰çŠ¶æ€ - åŒ…å«GPUå†…å­˜æ¸…ç†"""
    gpu_optimizer.clear_memory_if_needed()
    return None, None, None, None, None, None, None, [(None, None)], "ğŸ”„ å·²é‡ç½®æ‰€æœ‰å†…å®¹ï¼ˆå«GPUå†…å­˜æ¸…ç†ï¼‰"

def get_gpu_info():
    """è·å–GPUä¿¡æ¯æ˜¾ç¤º"""
    gpu_status = gpu_optimizer.get_gpu_status()
    if "error" in gpu_status:
        return "ğŸ–¥ï¸ CPUæ¨¡å¼è¿è¡Œ"

    return (
        f"ğŸš€ {gpu_status['gpu_name']} | "
        f"ğŸ’¾ æ˜¾å­˜: {gpu_status['memory_usage_percent']:.1f}% | "
        f"ğŸ”¥ æ¸©åº¦: {gpu_status['temperature_celsius']:.1f}Â°C | "
        f"âš¡ åˆ©ç”¨ç‡: {gpu_status['gpu_utilization_percent']:.1f}%"
    )

# ä¼˜åŒ–ç‰ˆCSSæ ·å¼ï¼ˆåŒ…å«GPUçŠ¶æ€æ˜¾ç¤ºï¼‰
optimized_css = """
/* åŸæœ‰CSSæ ·å¼åŸºç¡€ä¸Šæ·»åŠ GPUçŠ¶æ€æ ·å¼ */
:root {
    --primary-color: #1e3a8a;
    --secondary-color: #3b82f6;
    --accent-color: #8b5cf6;
    --success-color: #10b981;
    --warning-color: #f59e0b;
    --error-color: #ef4444;
    --gpu-color: #06b6d4;
    --bg-gradient: linear-gradient(135deg, #1e3a8a 0%, #3b82f6 100%);
}

.gradio-container {
    background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
}

.gpu-status {
    background: linear-gradient(135deg, var(--gpu-color), var(--accent-color));
    color: white;
    padding: 0.75rem 1rem;
    border-radius: 0.5rem;
    margin: 0.5rem 0;
    font-weight: 600;
    text-align: center;
    box-shadow: 0 4px 16px rgba(6, 182, 212, 0.3);
}

.performance-indicator {
    display: inline-block;
    width: 8px;
    height: 8px;
    border-radius: 50%;
    margin-right: 0.5rem;
    background: var(--success-color);
    animation: pulse 2s infinite;
}

@keyframes pulse {
    0% { opacity: 1; }
    50% { opacity: 0.5; }
    100% { opacity: 1; }
}

/* å…¶ä»–åŸæœ‰æ ·å¼ä¿æŒä¸å˜ */
.main-header {
    background: var(--bg-gradient);
    color: white;
    padding: 2rem;
    border-radius: 1rem;
    margin-bottom: 1.5rem;
    text-align: center;
    box-shadow: 0 8px 32px rgba(30, 58, 138, 0.3);
}

.main-header h1 {
    font-size: 2.5rem;
    font-weight: 700;
    margin: 0;
    text-shadow: 0 2px 4px rgba(0,0,0,0.3);
}

.status-indicator {
    padding: 0.75rem 1rem;
    border-radius: 0.5rem;
    margin: 0.5rem 0;
    font-weight: 500;
    border-left: 4px solid;
}

.status-success {
    background: #ecfdf5;
    color: #065f46;
    border-color: var(--success-color);
}

.status-error {
    background: #fef2f2;
    color: #991b1b;
    border-color: var(--error-color);
}

.status-info {
    background: #eff6ff;
    color: #1e40af;
    border-color: var(--primary-color);
}

.primary-btn {
    background: var(--bg-gradient) !important;
    color: white !important;
    border: none !important;
    padding: 0.75rem 2rem !important;
    border-radius: 0.5rem !important;
    font-weight: 600 !important;
    font-size: 1rem !important;
    transition: all 0.3s ease !important;
    box-shadow: 0 4px 16px rgba(30, 58, 138, 0.3) !important;
}

.primary-btn:hover {
    transform: translateY(-2px) !important;
    box-shadow: 0 8px 24px rgba(30, 58, 138, 0.4) !important;
}

.model-viewer {
    border-radius: 0.75rem;
    overflow: hidden;
    box-shadow: 0 4px 16px rgba(0, 0, 0, 0.1);
}

.section-title {
    color: var(--primary-color);
    font-size: 1.3rem;
    font-weight: 700;
    margin-bottom: 1rem;
    padding-bottom: 0.5rem;
    border-bottom: 2px solid #e2e8f0;
}

.param-group {
    background: #f8fafc;
    border-radius: 0.5rem;
    padding: 1rem;
    margin: 0.5rem 0;
    border: 1px solid #e2e8f0;
}

.examples-gallery {
    background: white;
    border-radius: 1rem;
    padding: 1.5rem;
    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
    margin-top: 2rem;
}

/* ç¤ºä¾‹å›¾ç‰‡æ ·å¼ */
.examples-gallery img, .example-image img {
    border-radius: 0.75rem;
    transition: all 0.3s ease;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    cursor: pointer;
    border: 2px solid transparent;
}

.examples-gallery img:hover, .example-image img:hover {
    transform: scale(1.05);
    box-shadow: 0 4px 16px rgba(30, 58, 138, 0.3);
    border-color: var(--primary-color);
}

.examples-gallery .gr-column {
    margin: 0.5rem;
}

.examples-gallery strong {
    color: var(--primary-color);
    font-size: 0.9rem;
}

.example-image {
    position: relative;
    overflow: hidden;
    border-radius: 0.75rem;
}

.example-image::after {
    content: "ç‚¹å‡»åŠ è½½";
    position: absolute;
    bottom: 0;
    left: 0;
    right: 0;
    background: linear-gradient(to top, rgba(30, 58, 138, 0.9), transparent);
    color: white;
    text-align: center;
    padding: 0.5rem;
    opacity: 0;
    transition: opacity 0.3s ease;
    font-size: 0.8rem;
}

.example-image:hover::after {
    opacity: 1;
}
"""

# åˆå§‹åŒ–æ€§èƒ½æ—¥å¿—
setup_performance_logging()

# åˆ›å»ºä¼˜åŒ–ç‰ˆGradioç•Œé¢
with gr.Blocks(css=optimized_css, title="Hunyuan3D-Part RTX GPUåŠ é€Ÿç‰ˆ") as demo:
    # é¡¶éƒ¨æ ‡é¢˜åŒºåŸŸ
    with gr.Row():
        gr.HTML("""
        <div class="main-header">
            <h1>âš¡ Hunyuan3D-Part RTX GPUåŠ é€Ÿç‰ˆ</h1>
            <p>ğŸš€ AIé©±åŠ¨çš„3Dæ¨¡å‹åˆ†æå·¥å…· | Flash Attention + æ··åˆç²¾åº¦ + torch.compileä¼˜åŒ–</p>
            <p>ğŸš€ äºŒæ¬¡å¼€å‘æ„å»ºbyç§‘å“¥ bugåé¦ˆå¾®ä¿¡ï¼š312088415</p>
        </div>
        """)

    # GPUçŠ¶æ€æ˜¾ç¤ºåŒºåŸŸ
    with gr.Row():
        gpu_status_display = gr.HTML(
            f'<div class="gpu-status"><span class="performance-indicator"></span>{get_gpu_info()}</div>',
            elem_classes=["gpu-status"]
        )

    # çŠ¶æ€æ˜¾ç¤ºåŒºåŸŸ
    with gr.Row():
        status_display = gr.HTML(
            '<div class="status-indicator status-info">ğŸ”µ RTX 4090 GPUå°±ç»ªï¼Œè¯·ä¸Šä¼ 3Dæ¨¡å‹å¼€å§‹åŠ é€Ÿå¤„ç†</div>',
            elem_classes=["status-display"]
        )

    # ä¸»è¦å†…å®¹åŒºåŸŸ
    with gr.Row():
        # å·¦ä¾§æ§åˆ¶é¢æ¿
        with gr.Column(scale=2):
            with gr.Group():
                gr.HTML('<div class="section-title">ğŸ“ 3Dæ¨¡å‹ä¸Šä¼ </div>')
                input_mesh = gr.Model3D(
                    label="æ”¯æŒæ ¼å¼ï¼šGLB, PLY, OBJ",
                    clear_color=[0.95, 0.95, 0.95, 1.0],
                    elem_classes=["model-viewer"]
                )

            # P3-SAMåˆ†å‰²å‚æ•°
            with gr.Group():
                gr.HTML('<div class="section-title">ğŸ” P3-SAM GPUåŠ é€Ÿåˆ†å‰²</div>')
                with gr.Group(elem_classes=["param-group"]):
                    with gr.Row():
                        segment_btn = gr.Button(
                            "âš¡ GPUåŠ é€Ÿåˆ†å‰²",
                            variant="primary",
                            size="lg",
                            elem_classes=["primary-btn"]
                        )
                        reset_btn = gr.Button(
                            "ğŸ”„ é‡ç½®+æ¸…ç†GPU",
                            variant="secondary"
                        )

                    with gr.Row():
                        p3sam_seed = gr.Number(
                            value=42,
                            label="ğŸ² éšæœºç§å­",
                            minimum=0,
                            maximum=9999,
                            step=1
                        )
                        postprocess = gr.Checkbox(
                            value=True,
                            label="âœ¨ åå¤„ç†ä¼˜åŒ–"
                        )

                    postprocess_threshold = gr.Slider(
                        minimum=0.1,
                        maximum=1.0,
                        value=0.95,
                        step=0.05,
                        label="ğŸ¯ åå¤„ç†é˜ˆå€¼"
                    )

            # XPartç”Ÿæˆå‚æ•°
            with gr.Group():
                gr.HTML('<div class="section-title">ğŸ› ï¸ XPart GPUåŠ é€Ÿç”Ÿæˆ</div>')
                with gr.Group(elem_classes=["param-group"]):
                    generate_btn = gr.Button(
                        "ğŸš€ GPUåŠ é€Ÿç”Ÿæˆ",
                        variant="primary",
                        size="lg",
                        elem_classes=["primary-btn"]
                    )
                    xpart_seed = gr.Number(
                        value=42,
                        label="ğŸ² ç”Ÿæˆç§å­",
                        minimum=0,
                        maximum=9999,
                        step=1
                    )

        # å³ä¾§ç»“æœå±•ç¤ºåŒºåŸŸ
        with gr.Column(scale=3):
            with gr.Tabs():
                # åˆ†å‰²ç»“æœé€‰é¡¹å¡
                with gr.TabItem("ğŸ” GPUåŠ é€Ÿåˆ†å‰²ç»“æœ"):
                    with gr.Group():
                        gr.HTML('<div class="section-title">P3-SAM GPUåˆ†å‰²ç»“æœ</div>')
                        segmented_mesh = gr.Model3D(
                            label="GPUåŠ é€Ÿåˆ†å‰²åçš„3Dæ¨¡å‹",
                            clear_color=[0.05, 0.05, 0.1, 1.0],
                            elem_classes=["model-viewer"]
                        )
                        face_id_file = gr.File(
                            label="ğŸ“„ é¢ç‰‡IDæ–‡ä»¶ä¸‹è½½"
                        )

                # ç”Ÿæˆç»“æœé€‰é¡¹å¡
                with gr.TabItem("ğŸ› ï¸ GPUåŠ é€Ÿç”Ÿæˆç»“æœ"):
                    with gr.Group():
                        gr.HTML('<div class="section-title">XPart GPUé›¶ä»¶ç”Ÿæˆç»“æœ</div>')

                        with gr.Row():
                            generated_parts = gr.Model3D(
                                label="ğŸ¯ GPUç”Ÿæˆçš„é›¶ä»¶",
                                clear_color=[0.05, 0.05, 0.1, 1.0],
                                elem_classes=["model-viewer"]
                            )
                            parts_with_bbox = gr.Model3D(
                                label="ğŸ“¦ å¸¦è¾¹ç•Œæ¡†çš„é›¶ä»¶",
                                clear_color=[0.05, 0.05, 0.1, 1.0],
                                elem_classes=["model-viewer"]
                            )

                        exploded_view = gr.Model3D(
                            label="ğŸ’¥ åˆ†è§£è§†å›¾",
                            clear_color=[0.05, 0.05, 0.1, 1.0],
                            elem_classes=["model-viewer"]
                        )

    # ç¤ºä¾‹å›¾åº“
    with gr.Group(elem_classes=["examples-gallery"]):
        gr.HTML('<div class="section-title">ğŸ¨ ç¤ºä¾‹æ¨¡å‹åº“</div>')
        gr.HTML('<p style="color: #64748b; margin-bottom: 1rem;">ç‚¹å‡»ç¤ºä¾‹å¿«é€Ÿä½“éªŒRTX 4090 GPUåŠ é€Ÿå¤„ç†</p>')

        # åˆ›å»ºå¸¦åç§°å’Œå›¾ç‰‡çš„ç¤ºä¾‹å±•ç¤º
        examples_info = [
            {"name": "å¥³æˆ˜å£«", "model": "P3-SAM/demo/assets/Female_Warrior.glb", "image": "P3-SAM/demo/assets/Female_Warrior.png"},
            {"name": "æ‚¬æµ®å²›", "model": "P3-SAM/demo/assets/Suspended_Island.glb", "image": "P3-SAM/demo/assets/Suspended_Island.png"},
            {"name": "ç”²è™«è½¦", "model": "P3-SAM/demo/assets/Beetle_Car.glb", "image": "P3-SAM/demo/assets/Beetle_Car.png"},
            {"name": "é”¦é²¤", "model": "XPart/data/Koi_Fish.glb", "image": "XPart/data/Koi_Fish.png"},
            {"name": "æ‘©æ‰˜è½¦", "model": "XPart/data/Motorcycle.glb", "image": "XPart/data/Motorcycle.png"},
            {"name": "é«˜è¾¾", "model": "XPart/data/Gundam.glb", "image": "XPart/data/Gundam.png"},
            {"name": "ç”µè„‘æ¡Œ", "model": "XPart/data/Computer_Desk.glb", "image": "XPart/data/Computer_Desk.png"},
            {"name": "å’–å•¡æœº", "model": "XPart/data/Coffee_Machine.glb", "image": "XPart/data/Coffee_Machine.png"},
        ]

        # åˆ›å»ºå›¾ç‰‡ç‚¹å‡»åŒºåŸŸ
        with gr.Row():
            example_images = []
            for i, info in enumerate(examples_info[:4]):  # ç¬¬ä¸€è¡Œ4ä¸ª
                with gr.Column(scale=1):
                    gr.HTML(f'<div style="text-align: center; margin-bottom: 0.5rem;"><strong>{info["name"]}</strong></div>')
                    img = gr.Image(
                        info["image"],
                        show_label=False,
                        height=120,
                        width=120,
                        elem_classes=["example-image"],
                        elem_id=f"example-img-{i}"
                    )
                    example_images.append(img)

        with gr.Row():
            for i, info in enumerate(examples_info[4:], 4):  # ç¬¬äºŒè¡Œ4ä¸ª
                with gr.Column(scale=1):
                    gr.HTML(f'<div style="text-align: center; margin-bottom: 0.5rem;"><strong>{info["name"]}</strong></div>')
                    img = gr.Image(
                        info["image"],
                        show_label=False,
                        height=120,
                        width=120,
                        elem_classes=["example-image"],
                        elem_id=f"example-img-{i}"
                    )
                    example_images.append(img)

        # ä¼ ç»Ÿçš„Examplesç»„ä»¶ä½œä¸ºå¤‡ç”¨
        example_inputs = gr.Examples(
            examples=[[info["model"]] for info in examples_info],
            inputs=[input_mesh],
            label="æˆ–ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®é€‰æ‹©æ¨¡å‹",
            examples_per_page=8,
            cache_examples=False
        )

    # éšè—çŠ¶æ€
    gr_state = gr.State(value=[(None, None)])

    # äº‹ä»¶ç»‘å®šå‡½æ•°
    def update_file_info(mesh_path):
        info = get_file_info(mesh_path)
        gpu_info = get_gpu_info()
        return (
            f'<div class="status-indicator status-info">ğŸ“ {info}</div>',
            f'<div class="gpu-status"><span class="performance-indicator"></span>{gpu_info}</div>'
        )

    def update_status_after_segment(status_msg):
        gpu_info = get_gpu_info()
        if status_msg.startswith("âœ…"):
            status_class = "status-success"
        else:
            status_class = "status-error"
        return (
            f'<div class="status-indicator {status_class}">{status_msg}</div>',
            f'<div class="gpu-status"><span class="performance-indicator"></span>{gpu_info}</div>'
        )

    def update_status_after_generate(status_msg):
        gpu_info = get_gpu_info()
        if status_msg.startswith("âœ…"):
            status_class = "status-success"
        else:
            status_class = "status-error"
        return (
            f'<div class="status-indicator {status_class}">{status_msg}</div>',
            f'<div class="gpu-status"><span class="performance-indicator"></span>{gpu_info}</div>'
        )

    # æ–‡ä»¶ä¸Šä¼ äº‹ä»¶
    input_mesh.change(
        fn=update_file_info,
        inputs=[input_mesh],
        outputs=[status_display, gpu_status_display]
    )

    # åˆ†å‰²äº‹ä»¶
    segment_btn.click(
        fn=segment_mesh_optimized,
        inputs=[input_mesh, postprocess, postprocess_threshold, p3sam_seed],
        outputs=[segmented_mesh, face_id_file, gr_state, status_display]
    ).then(
        fn=update_status_after_segment,
        inputs=[status_display],
        outputs=[status_display, gpu_status_display]
    )

    # ç”Ÿæˆäº‹ä»¶
    generate_btn.click(
        fn=generate_parts_optimized,
        inputs=[input_mesh, xpart_seed, gr_state],
        outputs=[generated_parts, parts_with_bbox, exploded_view, status_display]
    ).then(
        fn=update_status_after_generate,
        inputs=[status_display],
        outputs=[status_display, gpu_status_display]
    )

    # ç¤ºä¾‹å›¾ç‰‡ç‚¹å‡»äº‹ä»¶
    def load_example_model(model_path):
        """åŠ è½½ç¤ºä¾‹æ¨¡å‹"""
        return model_path, f'<div class="status-indicator status-info">ğŸ“ å·²é€‰æ‹©ç¤ºä¾‹æ¨¡å‹: {os.path.basename(model_path)}</div>'

    # ä¸ºæ¯ä¸ªç¤ºä¾‹å›¾ç‰‡æ·»åŠ ç‚¹å‡»äº‹ä»¶
    examples_models = [info["model"] for info in examples_info]
    for i, (img, model_path) in enumerate(zip(example_images, examples_models)):
        img.select(
            fn=lambda model=model_path: load_example_model(model),
            outputs=[input_mesh, status_display]
        )

    # é‡ç½®äº‹ä»¶
    reset_btn.click(
        fn=reset_all_optimized,
        outputs=[
            input_mesh, segmented_mesh, face_id_file,
            generated_parts, parts_with_bbox, exploded_view,
            status_display, gr_state, gpu_status_display
        ]
    )

if __name__ == '__main__':
    # å¯åŠ¨æ—¶æ˜¾ç¤ºGPUçŠ¶æ€
    gpu_optimizer.logger.info("=== RTX 4090 GPUåŠ é€Ÿç‰ˆå¯åŠ¨ ===")
    gpu_status = gpu_optimizer.get_gpu_status()

    if "error" not in gpu_status:
        gpu_optimizer.logger.info(f"GPU: {gpu_status['gpu_name']}")
        gpu_optimizer.logger.info(f"æ˜¾å­˜: {gpu_status['memory_total_mb']:.0f}MB")
        gpu_optimizer.logger.info(f"è®¡ç®—èƒ½åŠ›: {gpu_status['compute_capability']}")

    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )